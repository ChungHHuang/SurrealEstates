{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train = pd.read_csv('housing_train.csv')\n",
    "housing_test = pd.read_csv('housing_test.csv')\n",
    "\n",
    "y_housing = pd.read_csv('y_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full Train dimension:', housing_train.shape)\n",
    "print('Y train dimension:', y_housing.shape)\n",
    "print('Test data dimension:', housing_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing_train, y_housing, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(alpha = 1, normalize=True)\n",
    "lasso = linear_model.Lasso(alpha= 0, normalize = True)\n",
    "elasticnet = linear_model.ElasticNet(alpha = 0.01, l1_ratio=0.5, normalize=False)\n",
    "clf = linear_model.SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "gbm = ensemble.GradientBoostingRegressor()\n",
    "rf = ensemble.RandomForestRegressor(n_estimators = 800, min_samples_split=5,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt',\n",
    "                                    max_depth = 92, bootstrap = False, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList =[ridge, lasso, elasticnet, clf, gbm, rf]\n",
    "modelSeries= pd.Series(modelList, index =[ 'Ridge', 'Lasso', 'Elasticnet', 'SGD', 'XGboost', 'Random Forest'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSeries.apply(lambda x:x.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.concat([modelSeries.apply(lambda x: x.score(X_train,y_train)),modelSeries.apply(lambda x: x.score(X_test,y_test)), \n",
    "                                    modelSeries.apply(lambda x: np.sqrt(mean_squared_error(x.predict(X_test), y_test)))],axis=1)\n",
    "\n",
    "ans.columns = ['train score', 'test score', 'rmse']\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_test_encoded = lab_enc.fit_transform(y_test)\n",
    "print(y_test_encoded)\n",
    "\n",
    "print(utils.multiclass.type_of_target(y_test))\n",
    "print(utils.multiclass.type_of_target(y_test.astype('int')))\n",
    "print(utils.multiclass.type_of_target(y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mistakes = 0 # the mistakes each individual tree makes\n",
    "confusion_pair = 0\n",
    "\n",
    "n_pairs = 0.5 * rf.n_estimators * (rf.n_estimators-1)\n",
    "for idx, tree in enumerate(rf.estimators_):\n",
    "    mistakes += confusion_matrix(tree.predict(X_test), y_test)\n",
    "    for idx2, tree2 in enumerate(rf.estimators_):\n",
    "            if idx2 == idx: continue\n",
    "            confusion_pair += confusion_matrix(tree.predict(X_test), tree2.predict(X_test))   \n",
    "print(\"Average per Tree Confusion:\")\n",
    "print(mistakes/rf.n_estimators*1.0)\n",
    "print(\"Aggregate Pairwise Confusion:\")\n",
    "print(confusion_pair/n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_prediction = rf.predict(X_test)\n",
    "en_mse = mean_squared_error(en_prediction, y_test)\n",
    "en_rsme = np.sqrt(en_mse)\n",
    "print('RF RMSE: %.2f' % en_rsme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### number of trees in random forest\n",
    "n_estimators =[int(x) for x in np.linspace(start =200, stop = \n",
    "                                           2000, num=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Max number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 110, num=11)]\n",
    "max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### min samples split a node\n",
    "min_samples_split = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create random grid\n",
    "random_grid ={'n_estimators':n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'max_depth': max_depth,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'min_samples_leaf': min_samples_leaf,\n",
    "             'bootstrap':bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using random grid to search for best hyperparameters\n",
    "### base mode\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions =\n",
    "                              random_grid, n_iter = 100, cv = 3, verbose =2,\n",
    "                              random_state=42,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Value error fix for refit model into rf_random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "print(y_train_encoded)\n",
    "\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(y_train_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### best parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as sp_rand\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(ridge.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={'alpha':sp_rand()}\n",
    "model = Ridge()\n",
    "research = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                             n_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.fit(X_train, y_train)\n",
    "print(research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(research.best_score_)\n",
    "print(research.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
